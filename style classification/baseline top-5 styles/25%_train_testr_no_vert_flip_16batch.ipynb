{"cells":[{"metadata":{},"cell_type":"markdown","source":"### default libraries from kaggle"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### checking dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/painter-by-numbers-resized/artist_info_full.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Style classification (top-<TOP_N> styles)"},{"metadata":{"trusted":true},"cell_type":"code","source":"TOP_N = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['style'].value_counts()[0:TOP_N]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"style_enc_dict = {}\nfor i, style in enumerate(df['style'].value_counts()[0:TOP_N].index.tolist()):\n    style_enc_dict[style] = i\nprint(style_enc_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_key(my_dict, val): \n    for key, value in my_dict.items(): \n        if val == value:\n            return key","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Encoding style names"},{"metadata":{"trusted":true},"cell_type":"code","source":"style_df = df[df['style'].isin(style_enc_dict.keys())]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"style_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"style_df['style'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"style_df['style'].update(style_df['style'].map(style_enc_dict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"style_df['style'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(style_df['style'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = style_df['style']\ny.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"style_df.drop(labels=['style'], axis=1, inplace=True)\nstyle_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = style_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_part, X_not_used, y_part, y_not_used = train_test_split(\\\n                                                    X, y,\\\n                                                    test_size=0.75, shuffle=True,\\\n                                                    stratify = y, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_part.shape,y_part.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\\\n                                                    X_part, y_part,\\\n                                                    test_size=0.20, shuffle=True,\\\n                                                    stratify = y_part, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape,y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = X_train.join(y_train)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = X_test.join(y_test)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport numpy as np\nimport torchvision\nimport matplotlib.pyplot as plt\nimport time\nimport copy\nfrom PIL import Image\nfrom torchvision import transforms, models\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\nimport random\nimport shutil \nimport cv2\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Adding telegram bot"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install knockknock","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from knockknock import telegram_sender\n\nCHAT_ID: int = 266478885\n@telegram_sender(token=\"647225942:AAF-biI_UdXDVOwhqBjFRcELwbTzdeidn0w\", chat_id=CHAT_ID)\ndef train_your_nicest_model(time_value=2):\n    import time\n    time.sleep(time_value)\n    return {'loss': 0.9} # Optional return value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_your_nicest_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Freezing random seeds"},{"metadata":{"trusted":true},"cell_type":"code","source":"RANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(RANDOM_SEED)\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ntorch.cuda.manual_seed(RANDOM_SEED)\ntorch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = '../input/painter-by-numbers-resized/'\nclass ImagesDataset(torch.utils.data.Dataset):\n    def __init__(self, df, transform = None,\n                 loader = torchvision.datasets.folder.default_loader):\n        self.df = df\n        self.transform = transform\n        self.loader = loader\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        target = row['style']\n        path = filepath + row['filename']\n        img = self.loader(path)\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, target\n\n    def __len__(self):\n        n, _ = self.df.shape\n        return n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# what transformations should be done with our images\ntrain_transforms = transforms.Compose([\n    transforms.RandomAffine(degrees=10, scale=(1.1, 1.3)),\n    transforms.RandomCrop((224, 224)),\n    transforms.RandomHorizontalFlip(),\n#     transforms.RandomVerticalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.RandomCrop((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initialize our dataset at first\ndataset = ImagesDataset(\n    df = train_df,\n    transform = train_transforms\n)\n\nbatch_size = 16\nvalidation_split = 0.2\nshuffle_dataset = True\n# Creating data indices for training and validation splits:\ndataset_size = len(train_df)\n\nindices = list(range(dataset_size))\nsplit = int(np.floor(validation_split * dataset_size))\nif shuffle_dataset:\n    np.random.seed(RANDOM_SEED)\n    np.random.shuffle(indices)\n\ntrain_indices, val_indices = indices[split:], indices[:split]\n\n# Creating PT data samplers and loaders:\ntrain_sampler = SubsetRandomSampler(train_indices)\nvalid_sampler = SubsetRandomSampler(val_indices)\n\ntrain_dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size, \n                                           sampler = train_sampler)\nval_dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size,\n                                                sampler = valid_sampler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_dataloader), len(train_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_batch, y_batch = next(iter(train_dataloader))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nplt.imshow(X_batch[0].permute(1, 2, 0).numpy() * std + mean);\nplt.title(get_key(style_enc_dict, int(y_batch[0])))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_input(input_tensor, title=''):\n    image = input_tensor.permute(1, 2, 0).numpy()\n    image = std * image + mean\n    \n    plt.imshow(image.clip(0, 1))\n    plt.title(title)\n    plt.show()\n    plt.pause(0.001)\n\nX_batch, y_batch = next(iter(train_dataloader))\n\niter_stop = 10\ni = 0\n\nfor x_item, y_item in zip(X_batch, y_batch):\n    show_input(x_item, title=get_key(style_enc_dict, y_item))\n    i += 1\n    if i > iter_stop:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n#     '''Calculate F1 score. Can work with gpu tensors\n    \n#     The original implmentation is written by Michal Haltuf on Kaggle.\n    \n#     Returns\n#     -------\n#     torch.Tensor\n#         `ndim` == 1. 0 <= val <= 1\n    \n#     Reference\n#     ---------\n#     - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n#     - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n#     - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n    \n#     '''\n#     assert y_true.ndim == 1\n#     assert y_pred.ndim == 1 or y_pred.ndim == 2\n    \n#     if y_pred.ndim == 2:\n#         y_pred = y_pred.argmax(dim=1)\n        \n    \n#     tp = (y_true * y_pred).sum().to(torch.float32)\n#     tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n#     fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n#     fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n    \n#     epsilon = 1e-7\n    \n#     precision = tp / (tp + fp + epsilon)\n#     recall = tp / (tp + fn + epsilon)\n    \n#     f1 = 2* (precision*recall) / (precision + recall + epsilon)\n#     f1.requires_grad = is_training\n#     return f1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"@telegram_sender(token=\"647225942:AAF-biI_UdXDVOwhqBjFRcELwbTzdeidn0w\", chat_id=CHAT_ID)\ndef model_print(epoch, num_epochs):\n    return \"Epoch: \" + str(epoch) + \"/\" + str(num_epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_accuracy_history = []\ntrain_loss_history = []\n# train_roc_auc_history = []\n\n\nval_accuracy_history = []\nval_loss_history = []\n# val_roc_auc_history = []\n\nres_model = None\n@telegram_sender(token=\"647225942:AAF-biI_UdXDVOwhqBjFRcELwbTzdeidn0w\", chat_id=CHAT_ID)\ndef train_model(model, loss, optimizer, num_epochs):\n    min_val_loss = 200.0\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}:'.format(epoch, num_epochs - 1), flush=True)\n        model_print(epoch, num_epochs - 1)\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                dataloader = train_dataloader\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                dataloader = val_dataloader\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.\n            running_acc = 0.\n            # running_roc_auc = 0.\n            \n            \n            # Iterate over data.\n            for inputs, labels in tqdm(dataloader):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                # forward and backward\n                with torch.set_grad_enabled(phase == 'train'):\n                    preds = model(inputs)\n                    loss_value = loss(preds, labels)\n                    preds_class = preds.argmax(dim=1)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss_value.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss_value.item()\n                running_acc += (preds_class == labels.data).float().mean()\n                # running_roc_auc += f1_loss(labels.data, preds_class).mean()\n                \n            epoch_loss = running_loss / len(dataloader)\n            epoch_acc = running_acc / len(dataloader)\n            # epoch_roc_auc = running_roc_auc / len(dataloader)\n            \n            if (phase == 'train'):\n                train_accuracy_history.append(epoch_acc)\n                train_loss_history.append(epoch_loss)\n                # train_roc_auc_history.append(epoch_roc_auc)\n                \n            elif (phase == 'val'):\n                if epoch_loss < min_val_loss:\n                    min_val_loss = epoch_loss\n                    with open('top_model', 'wb') as f:\n                        torch.save(model, f)\n                val_accuracy_history.append(epoch_acc)\n                val_loss_history.append(epoch_loss)\n                # val_roc_auc_history.append(epoch_roc_auc)\n                \n            print('{} loss: {:.4f} acc: {:.4f}'.format(phase, epoch_loss, \\\n                                                       epoch_acc), flush=True)\n    print('top model with min_val_loss:', min_val_loss)\n    return 'Success'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet50(pretrained=True)\n\n# Disable grad for all conv layers\nfor param in model.parameters():\n    t = param\n    param.requires_grad = False\n\nnum_ftrs = model.fc.in_features\nmodel.fc = torch.nn.Linear(num_ftrs, TOP_N)\n# model.bn = torch.nn.BatchNorm1d(num_ftrs)\n# model.fc = torch.nn.Linear(num_ftrs, int(num_ftrs / 2))\n# num_ftrs = model.fc.in_features\n\n# model.act1 = torch.nn.LeakyReLU()\n# model.fc2 = torch.nn.Linear(num_ftrs, TOP_N)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nloss = torch.nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), amsgrad=True, lr=1.0e-3)\n\n# Decay LR by a factor of 0.1 every 10 epochs\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dataloader))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model(model, loss, optimizer, num_epochs=100);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_accuracy_history, label='train_acc')\nplt.plot(val_accuracy_history, label='val_acc')\nplt.legend()\nplt.title('Accuracy');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train_loss_history, label='train_loss')\nplt.plot(val_loss_history, label='val_loss')\nplt.legend()\nplt.title('Loss');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plt.plot(train_roc_auc_history, label='train_f1')\n# plt.plot(val_roc_auc_history, label='val_f1')\n# plt.legend()\n# plt.title('f1');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\\\n                                                    X, y,\\\n                                                    test_size = 0.20, shuffle = True,\\\n                                                    stratify = y, random_state = RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df_full = X_test_full.join([y_test_full])\ntest_df_full.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = ImagesDataset(\n    df = test_df_full,\n    transform = val_transforms\n)\n\ntest_dataloader = torch.utils.data.DataLoader(dataset, batch_size = batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_batch, y_batch = next(iter(test_dataloader))\nmean = np.array([0.485, 0.456, 0.406])\nstd = np.array([0.229, 0.224, 0.225])\nplt.imshow(X_batch[0].permute(1, 2, 0).numpy() * std + mean);\nplt.title(get_key(style_enc_dict, int(y_batch[0])))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the best saved model.\nwith open('top_model', 'rb') as f:\n    model = torch.load(f)\nmodel.eval()\n\ntest_labels = []\ntest_predictions = []\ntest_predictions_class = []\ntest_batch_loss = 0.0\ntest_batch_acc = 0.0\n\nfor inputs, labels in tqdm(test_dataloader):\n    inputs = inputs.to(device)\n    for element in labels:\n        test_labels.append(int(element))\n    labels = labels.to(device)\n    with torch.set_grad_enabled(False):\n        preds = model(inputs)\n        loss_value = loss(preds, labels)\n        preds_class = preds.argmax(dim=1)\n        for element in preds_class:\n            test_predictions_class.append(int(element))\n    test_batch_loss += loss_value.item()\n    test_batch_acc += (preds_class == labels.data).float().mean()\n    test_predictions.append(\n        torch.nn.functional.softmax(preds, dim=1)[:,1].data.cpu().numpy())\n    \ntest_predictions = np.concatenate(test_predictions)\n\ntest_loss = test_batch_loss / len(test_dataloader)\ntest_acc = test_batch_acc / len(test_dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('test_loss:', test_loss)\nprint('test_acc:', float(test_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'top_model')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}